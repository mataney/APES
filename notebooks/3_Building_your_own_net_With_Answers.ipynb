{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Building your own net - With Answers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mataney/APES/blob/master/notebooks/3_Building_your_own_net_With_Answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMC5O5ZFRQiy",
        "colab_type": "text"
      },
      "source": [
        "# Train your own network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeFlVjP_6fQ0",
        "colab_type": "text"
      },
      "source": [
        "## Load CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6t2BtzuR84A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grf0qWK-Pwfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU45DMNbalAn",
        "colab_type": "code",
        "outputId": "66bafb35-b68f-4217-9a1b-38010cfc0fae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paQT8mxpmuOi",
        "colab_type": "text"
      },
      "source": [
        "### Train and Evaluation loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxqgplA_m0xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, num_epochs, trainloader, optimizer, criterion, device):\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          if i % 200 == 199:    # print every 200 mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 200))\n",
        "              running_loss = 0.0\n",
        "\n",
        "  print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXnOhGJzmBYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for data in dataloader:\n",
        "          inputs, labels = data\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "      100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0ZjY0198Euf",
        "colab_type": "text"
      },
      "source": [
        "## More Transformations!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m2SLELQySxf",
        "colab_type": "text"
      },
      "source": [
        "### Description\n",
        "\n",
        "Before we update our model, lets try to give it better inputs.  \n",
        "Let's add \n",
        " - Data Augmentation (more -> better)\n",
        " - Normalizing the input images (Theoreticall, your network will train better when the inputs are normalized, related to the way the weights are initialized).\n",
        "How to do this:  \n",
        "\n",
        "We define a `transform` instance and read our data using it.  \n",
        "Reread the **train data** with your own `transform` instance.\n",
        "\n",
        "- Horizontally flip the given PIL Image randomly with a given probability, use default probability. \n",
        " - **Hint:** Look at [`RandomHorizontalFlip`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomHorizontalFlip).\n",
        "-  Normalize the inputs such that the mean and standard deviation are 0, 1 respectively for each channel. \n",
        "  - Normalize using standard normalization:  \n",
        "    $x' = \\frac{x-\\mu}{\\sigma}$, or  \n",
        "    `input[channel] = (input[channel]-mean[channel]) / std[channel]`  \n",
        "  - **Hint:** use [Normalize](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomHorizontalFlip)  to preform such transformation.  \n",
        "    We need 2 vectors of size `channels`, to represent the mean and std of each channel, find these.\n",
        "- Don't forget to use the same `ToTensor` transformation we used.\n",
        "\n",
        "Reread the **test data** using the same normalization as the train data, but don't augment the data. (Again, don't forget to use `ToTensor`)\n",
        "\n",
        "\n",
        "Yes, you can do this in python with loops etc, but try to do this with native Torch native methods, `mean()`, `std()` etc'.  \n",
        "**Hint:** You will probably want to stack all the images to one tensor. use `torch.stack([t[0] for t in trainset])` then you will have a `[50000, 3, 32, 32]` size tensor with all the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eltDLlPiMKf4",
        "colab_type": "text"
      },
      "source": [
        "### Your Implemention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCy-yeOMNEnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoHoeWTnMOJt",
        "colab_type": "text"
      },
      "source": [
        "### View implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bXgijweMi6M",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look on the train data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYnpwxUcNOl_",
        "colab_type": "text"
      },
      "source": [
        "We need to check the mean and std of the data, for this we need to have an iterable object of the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhjVKqNSlifC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensored_trainset = torch.stack([t[0] for t in trainset])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkq79k2rpqvP",
        "colab_type": "code",
        "outputId": "e62e57bf-9af4-462a-f0a1-ff8491a36204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(tensored_trainset.size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50000, 3, 32, 32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBGHptMspuiO",
        "colab_type": "text"
      },
      "source": [
        "A small note about calculating the mean and std.  \n",
        "what is the right why of calculating the std for example?  \n",
        "Should we assume nothing and find the std for each image, then normalize w.r.t each image's std? - this will result with a distribution with 0, 1 mean, std respectively.\n",
        "Should we assume all the images are coming from the same distribution and by that we can just find calculate the std of all the images at once? - this as well will result with a distribution with 0, 1 mean, std respectively.\n",
        "\n",
        "For now, assume the latter.  \n",
        "\n",
        "So, let's find mean and std for each channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LaX8D0cprlv",
        "colab_type": "code",
        "outputId": "095e27ec-0b44-408d-aa0c-b8346b24f0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(tensored_trainset.mean([0, 2, 3]))\n",
        "print(tensored_trainset.std([0, 2, 3]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.4914, 0.4822, 0.4465])\n",
            "tensor([0.2470, 0.2435, 0.2616])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJO8CaeTXjIo",
        "colab_type": "text"
      },
      "source": [
        "Define transformations with the mean and std we found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaDHOi73mVHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv9tn_6BVlh1",
        "colab_type": "code",
        "outputId": "a9260c35-b354-4df8-db4f-f3d9e4c1f2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5e4ENYdXxhg",
        "colab_type": "text"
      },
      "source": [
        "Let's sanity check that it is normalized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bG8s80OXq59t",
        "colab_type": "code",
        "outputId": "0677ed89-87f6-4744-de2a-978d5f151cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tensored_trainset = torch.stack([t[0] for t in trainset])\n",
        "print(tensored_trainset.mean([0, 2, 3]))\n",
        "print(tensored_trainset.std([0, 2, 3]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.2867e-06, -1.7074e-04,  1.1819e-04])\n",
            "tensor([1.0001, 0.9999, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv3g7uXDg9ms",
        "colab_type": "text"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS-Ht6Zwrb3N",
        "colab_type": "text"
      },
      "source": [
        "Define the following CNN:\n",
        " - It should have a 3 Convolution layers.\n",
        " - It should have a Deep FC layer.\n",
        " \n",
        " \n",
        " Let's start with the latter part:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny3j2FVuxwCC",
        "colab_type": "text"
      },
      "source": [
        "## Deep Fully Connected\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mqkh3P5DoVl",
        "colab_type": "text"
      },
      "source": [
        "While it will be the latter layer of our network, let's start with the Deep FC network.  \n",
        "We  should define such network in an independent way from CNN,  \n",
        "so when we want to reuse it, we can.\n",
        "\n",
        "Define the following network (x is input)\n",
        "\n",
        "$x \\rightarrow dropout \\rightarrow linearLayer_1 \\rightarrow relu \\rightarrow linearLayer_2 \\rightarrow relu \\rightarrow dropout \\rightarrow linearLayer_3$\n",
        "\n",
        "Make the The input/hidden/output sizes and the Dropout probability decided by the constructor arugments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjIvQE5mxoNP",
        "colab_type": "text"
      },
      "source": [
        "### Your implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d4xe-Vqxn_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FC(nn.Module):\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ODQR1WWxqXn",
        "colab_type": "text"
      },
      "source": [
        "### View implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqTeBNONseQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FC(nn.Module):\n",
        "  def __init__(self, in_size1, in_size2, in_size3, out_size, drop_prob):\n",
        "    super(FC, self).__init__()\n",
        "    self.linear1 = nn.Linear(in_size1, in_size2)\n",
        "    self.linear2 = nn.Linear(in_size2, in_size3)\n",
        "    self.out_linear = nn.Linear(in_size3, out_size)\n",
        "    \n",
        "    self.drop = nn.Dropout(drop_prob)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    x = self.drop(x)\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.drop(x)\n",
        "    x = self.out_linear(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ4tQTXz0bk0",
        "colab_type": "text"
      },
      "source": [
        "## Deep Convolution Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtzegqpW0oR3",
        "colab_type": "text"
      },
      "source": [
        "We want to define a single Deep Convolution network\n",
        "\n",
        "Define the following network (x is input)\n",
        "\n",
        "$x \\rightarrow ConvLayer_1 \\rightarrow batch~normalization \\rightarrow relu \\rightarrow ConvLayer_2 \\rightarrow relu \\rightarrow pooling \\rightarrow dropout $\n",
        "\n",
        "Each ConvLayer is defined with a few arguments: \n",
        "- number of input channels\n",
        "- number of output channels\n",
        "- kernel size\n",
        "- padding\n",
        "\n",
        "(There are other arguments, like stride and dilation, we won't use these here)\n",
        "\n",
        "Set these accordingly:  \n",
        "- Set $Convolution_1$ to be `(c_in, c_hidden, 3, 1)` respectively.  \n",
        "- Set $Convolution_2$ to be `(c_hidden, c_out, 3, 1)` respectively.  \n",
        "(Hint: Check out `nn.Conv2d`)\n",
        "\n",
        "- Set Batch Normalization to be the same size as $Convolution_1$ output (`c_out`).  \n",
        "(Hint: Check out `nn.BatchNorm2d`)\n",
        "\n",
        "- Set pooling of `kernel_size=2` and `stride=2`.  \n",
        "(Hint: Check out `nn.MaxPool2d`)\n",
        "\n",
        "- Set Dropout with dropout probability of `.0`.  \n",
        "(Hint: Check out `nn.Dropout2d`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbmFokrA0j5S",
        "colab_type": "text"
      },
      "source": [
        "### Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q4Jdn1a0mxY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepConvLayer(nn.Module):\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvCU3FZk0hVL",
        "colab_type": "text"
      },
      "source": [
        "### View Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROEkLKsp1rpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepConvLayer(nn.Module):\n",
        "  def __init__(self, in_channels, conv1_out_channels, conv2_out_channels, drop_prob=.0):\n",
        "    super(DeepConvLayer, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
        "                           out_channels=conv1_out_channels,\n",
        "                           kernel_size=3, padding=1)\n",
        "    self.batch_norm = nn.BatchNorm2d(conv1_out_channels) \n",
        "    self.conv2 = nn.Conv2d(in_channels=conv1_out_channels,\n",
        "                           out_channels=conv2_out_channels,\n",
        "                           kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.drop = nn.Dropout2d(p=drop_prob)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.batch_norm(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.pool(x)\n",
        "    x = self.drop(x)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tvOS_fq8pbX",
        "colab_type": "text"
      },
      "source": [
        "## Deep CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6IVW0T08uOy",
        "colab_type": "text"
      },
      "source": [
        "After we have these 2 new network, let's use them to create our end2end CNN model.\n",
        "\n",
        "Define the following network (x is input)\n",
        "\n",
        "$x \\rightarrow DeepConvLayer_1 \\rightarrow DeepConvLayer_2 \\rightarrow DeepConvLayer_3 \\rightarrow FC$\n",
        "\n",
        "You can also stack the three DeepConvLayers to a single layer using the `nn.Sequential` function. Give this a go.\n",
        "\n",
        "For our ConvLayers set `(c_in, c_hidden, c_out, dropout_p=.0)` to be:  \n",
        "- $DeepConvLayer_1:$ `(3, 32, 64)` respectively.\n",
        "- $DeepConvLayer_2:$ `(64, 128, 128, 0.05)` respectively.\n",
        "- $DeepConvLayer_3:$ `(128, 256, 256)` respectively.\n",
        "\n",
        "For the FC, set  \n",
        "- The input/hidden/output sizes are 4096, 1024, 512, 10.  \n",
        "- Dropout probability is 0.1\n",
        "\n",
        "\n",
        "\n",
        "**Something you might require to think about:**  \n",
        "You should always keep track of the sizes the input is receiving and returning.  \n",
        "For example, what is the output of size the third convolution?  \n",
        "what is the input size of the FC?  \n",
        "This is not an easy one, you can just run and see why it collapses, as we did before :)  \n",
        "Do these match?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Hg7yxICQp1",
        "colab_type": "text"
      },
      "source": [
        "### Your Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geWgJGPmCQic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRIPQ78wCQX5",
        "colab_type": "text"
      },
      "source": [
        "### View Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCyfJT5OcS2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv = nn.Sequential(DeepConvLayer(3, 32, 64), \n",
        "                                  DeepConvLayer(64, 128, 128, 0.05),\n",
        "                                  DeepConvLayer(128, 256, 256))\n",
        "        self.fc_layer = FC(4096, 1024, 512, 10, 0.1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EGAInjKCers",
        "colab_type": "text"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ9UtQP-CjZw",
        "colab_type": "text"
      },
      "source": [
        "Initialize and set to run on CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oVYO-IvI5kUL",
        "colab": {}
      },
      "source": [
        "model = CNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qz64p18CLtA",
        "colab_type": "code",
        "outputId": "3a0b5a7b-381a-4fe2-a75d-db59665461d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv): Sequential(\n",
              "    (0): DeepConvLayer(\n",
              "      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (drop): Dropout2d(p=0.0)\n",
              "    )\n",
              "    (1): DeepConvLayer(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (drop): Dropout2d(p=0.05)\n",
              "    )\n",
              "    (2): DeepConvLayer(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (drop): Dropout2d(p=0.0)\n",
              "    )\n",
              "  )\n",
              "  (fc_layer): FC(\n",
              "    (linear1): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (out_linear): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (drop): Dropout(p=0.1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tS971trh-Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-08)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50z8thS8n1Op",
        "colab_type": "code",
        "outputId": "8250f717-cdde-402a-9f97-d8204f1deac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_epochs = 10\n",
        "train(model, num_epochs, trainloader, optimizer, criterion, device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,   200] loss: 1.883\n",
            "[1,   400] loss: 1.596\n",
            "[1,   600] loss: 1.453\n",
            "[1,   800] loss: 1.374\n",
            "[1,  1000] loss: 1.271\n",
            "[1,  1200] loss: 1.202\n",
            "[1,  1400] loss: 1.134\n",
            "[2,   200] loss: 1.054\n",
            "[2,   400] loss: 1.014\n",
            "[2,   600] loss: 0.969\n",
            "[2,   800] loss: 0.965\n",
            "[2,  1000] loss: 0.901\n",
            "[2,  1200] loss: 0.901\n",
            "[2,  1400] loss: 0.869\n",
            "[3,   200] loss: 0.818\n",
            "[3,   400] loss: 0.798\n",
            "[3,   600] loss: 0.776\n",
            "[3,   800] loss: 0.780\n",
            "[3,  1000] loss: 0.791\n",
            "[3,  1200] loss: 0.758\n",
            "[3,  1400] loss: 0.740\n",
            "[4,   200] loss: 0.706\n",
            "[4,   400] loss: 0.692\n",
            "[4,   600] loss: 0.678\n",
            "[4,   800] loss: 0.673\n",
            "[4,  1000] loss: 0.684\n",
            "[4,  1200] loss: 0.673\n",
            "[4,  1400] loss: 0.672\n",
            "[5,   200] loss: 0.618\n",
            "[5,   400] loss: 0.617\n",
            "[5,   600] loss: 0.612\n",
            "[5,   800] loss: 0.621\n",
            "[5,  1000] loss: 0.621\n",
            "[5,  1200] loss: 0.614\n",
            "[5,  1400] loss: 0.597\n",
            "[6,   200] loss: 0.567\n",
            "[6,   400] loss: 0.543\n",
            "[6,   600] loss: 0.559\n",
            "[6,   800] loss: 0.557\n",
            "[6,  1000] loss: 0.563\n",
            "[6,  1200] loss: 0.558\n",
            "[6,  1400] loss: 0.549\n",
            "[7,   200] loss: 0.490\n",
            "[7,   400] loss: 0.510\n",
            "[7,   600] loss: 0.551\n",
            "[7,   800] loss: 0.513\n",
            "[7,  1000] loss: 0.521\n",
            "[7,  1200] loss: 0.495\n",
            "[7,  1400] loss: 0.503\n",
            "[8,   200] loss: 0.468\n",
            "[8,   400] loss: 0.448\n",
            "[8,   600] loss: 0.454\n",
            "[8,   800] loss: 0.461\n",
            "[8,  1000] loss: 0.467\n",
            "[8,  1200] loss: 0.485\n",
            "[8,  1400] loss: 0.481\n",
            "[9,   200] loss: 0.412\n",
            "[9,   400] loss: 0.450\n",
            "[9,   600] loss: 0.432\n",
            "[9,   800] loss: 0.433\n",
            "[9,  1000] loss: 0.453\n",
            "[9,  1200] loss: 0.432\n",
            "[9,  1400] loss: 0.435\n",
            "[10,   200] loss: 0.400\n",
            "[10,   400] loss: 0.394\n",
            "[10,   600] loss: 0.403\n",
            "[10,   800] loss: 0.417\n",
            "[10,  1000] loss: 0.406\n",
            "[10,  1200] loss: 0.401\n",
            "[10,  1400] loss: 0.417\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91ootx5whsDU",
        "colab_type": "text"
      },
      "source": [
        "## Saving the Model\n",
        "\n",
        "We are using Notebooks, so it is not a problem to use the trained model the next cell.  \n",
        "But what if this is not the case and we want to save and load our model.\n",
        "\n",
        "What should we do?\n",
        "\n",
        "one option is:\n",
        "```\n",
        "torch.save(model, PATH)\n",
        "...\n",
        "model = torch.load(PATH)\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "This save/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Pythonâ€™s pickle module. The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors.\n",
        "\n",
        "A more recommended way is:\n",
        "\n",
        "```\n",
        "torch.save(model.state_dict(), PATH)\n",
        "...\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "```\n",
        "\n",
        "What about other components in our code?\n",
        "You should:\n",
        "```\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            ...\n",
        "            }, PATH)\n",
        "...\n",
        "model = TheModelClass(*args, **kwargs)\n",
        "optimizer = TheOptimizerClass(*args, **kwargs)\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IFoiQeZip5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './model'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP57_qQrm2_G",
        "colab_type": "text"
      },
      "source": [
        "### Test the network on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JLeFt0irzmN",
        "colab_type": "code",
        "outputId": "987919c8-5124-42b1-8dac-1940e143f77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "model = CNN()\n",
        "print(model.conv[0].conv1.weight[0, 0 , 0, 0])\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "print(model.conv[0].conv1.weight[0, 0 , 0, 0])\n",
        "model.to(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-0.0964, grad_fn=<SelectBackward>)\n",
            "tensor(-0.0273, grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv): Sequential(\n",
              "    (0): DeepConvLayer(\n",
              "      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (drop): Dropout2d(p=0.0)\n",
              "    )\n",
              "    (1): DeepConvLayer(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (batch_norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (drop): Dropout2d(p=0.05)\n",
              "    )\n",
              "    (2): DeepConvLayer(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (drop): Dropout2d(p=0.0)\n",
              "    )\n",
              "  )\n",
              "  (fc_layer): FC(\n",
              "    (linear1): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "    (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (out_linear): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (drop): Dropout(p=0.1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADXLq0WvZqGw",
        "colab_type": "code",
        "outputId": "2c6a85c1-2fd4-4053-a5b6-e8b1820c1448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "evaluate(model, testloader, device)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 83 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H48XLoWbAoe",
        "colab_type": "text"
      },
      "source": [
        "Source: https://zhenye-na.github.io/2018/09/28/pytorch-cnn-cifar10.html  \n",
        "https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py  \n",
        "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P67DkaO5QA4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}